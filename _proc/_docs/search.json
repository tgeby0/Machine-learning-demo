[
  {
    "objectID": "mnist.html",
    "href": "mnist.html",
    "title": "Machine-learning-demo",
    "section": "",
    "text": "# Run this block and make sure it is successful.\nimport numpy as np  # used for handling mathematical operations easier in python\nimport tensorflow as tf  # used for creating and training machine learning models \nfrom tensorflow import keras # Keras contains the mnist dataset\nfrom matplotlib import pyplot as plt  # library that helps us visualize data by creating plots \nimport seaborn as sn # visualization library for creating more complex graphs\n\n\n\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() \n#TODO: Add the split data line here\n\n\ndef plotImage(index,x_train,x_test,y_train):\n    # Normalize the values so they are a decimal between 0 and 1\n    x_train = x_train/255\n    x_test = x_test/255\n    print(f'The plot represents the number {y_train[index]}')\n    plt.imshow(x_train[index],cmap = plt.cm.binary )\n    plt.show()\n\nplotImage(54, x_train, x_test, y_train)\n#TODO: change the index to see other values in the dataset\n\nThe plot represents the number 9\n\n\n\n\n\n\n\n\n\n\n# TODO: Add reshape the data in this code block\n\nx_train_flat = x_train.reshape(len(x_train), 784)\nx_test_flat = x_test.reshape(len(x_test), 784)\n\n\n# Model creation\nmodel = keras.Sequential([\n    keras.layers.Dense(128, input_shape = (784,),activation='relu'), \n    keras.layers.Dense(64, activation='sigmoid'), \n    keras.layers.Dense(32, activation='sigmoid'), \n    keras.layers.Dense(10, activation='sigmoid')\n])\nmodel.compile (\n    optimizer='adam',\n    loss = 'sparse_categorical_crossentropy',\n    metrics = ['accuracy']\n)\n\n/Users/tgeby/Documents/GitHub/Machine-learning-demo/venv/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n\n\n\nmodel.fit(x_train_flat, y_train, epochs=5)\n# TODO: Train the model using model.fit here\n\nEpoch 1/5\n1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 955us/step - accuracy: 0.7280 - loss: 1.1109\nEpoch 2/5\n1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 964us/step - accuracy: 0.9087 - loss: 0.3159\nEpoch 3/5\n1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 970us/step - accuracy: 0.9128 - loss: 0.2981\nEpoch 4/5\n1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 940us/step - accuracy: 0.9204 - loss: 0.2675\nEpoch 5/5\n1875/1875 ━━━━━━━━━━━━━━━━━━━━ 2s 938us/step - accuracy: 0.9278 - loss: 0.2453\n\n\n&lt;keras.src.callbacks.history.History at 0x13d8f8510&gt;\n\n\n\nmodel.evaluate(x_test_flat, y_test)\n# TODO: Test the model against the test data using model.evaluate\n\n313/313 ━━━━━━━━━━━━━━━━━━━━ 0s 376us/step - accuracy: 0.9215 - loss: 0.2544\n\n\n[0.2291691154241562, 0.9297000169754028]\n\n\n\n# TODO: Run the confusion matrix\ndef plot_confusion_matrix(model, x_test_flat, y_test):\n    # Make predictions\n    y_pred = model.predict(x_test_flat)\n    y_pred_labels = [np.argmax(i) for i in y_pred]\n    # Create confusion matrix\n    confusion_matrix = tf.math.confusion_matrix(labels=y_test, predictions=y_pred_labels)\n    # Plot the confusion matrix\n    plt.figure(figsize=(8, 6))\n    sn.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.show()\n\n# TODO: Uncomment out the line below and run the code block\nplot_confusion_matrix(model,x_test_flat,y_test)\n\n313/313 ━━━━━━━━━━━━━━━━━━━━ 0s 423us/step",
    "crumbs": [
      "mnist.html"
    ]
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "Machine Learning Homework",
    "section": "",
    "text": "For this homework you will be training and testing a machine learning model that will be able to predict handwriting using the MNIST dataset.\n\n\nStep 1: Setup\n\nrun pip install -r requirements.txt\nGo to the file mnist.ipynb in nbs\nRun the first code block with the imports and make sure it is successful\n\n\n\nStep 2: Splitting the data\n\nNext we want to get the mnist dataset and split the data into a training and a testing set\nto do this, add the line (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() to the next code block\nx_train & x_test: x_train and x_test are the mnist images themselves. They are represented as 28x28 2D arrays where each value is a number between 0, which represents the color white, and 255 which is black.\ny_train & y_test: The y values are the actual number that the image represents.\n\n\n\n\nIn this image, the y value is the label and the x value is the image\n\n\n\n\nStep 3: Visualize the data\n\nTo visualize the 2D array, use the function matplotlib library\nRun the function plotImage to plot the data\nChange the index to see different numbers and images that are in the dataset\n\n\n\nStep 4: Reshape the data\n\nThe neural network is expecting a 1D array, so we will need to reshape our data before we can train the model\nWe currently have a 28x28 2D matrix for every value in the dataset. We need to reshape each value to be a single array with a length of 784 containing all of the same values. \nTo do this we do the following  x_train_flat = x_train.reshape(NumberOfRows, NumberOfColumns)\nNumberOfRows: Represents the number of rows in the new array. For this dataset, the number of rows should be the length of x_train\nNumberOfColumns: Represents the number of elements we want to represent each image, or 784\nWe need to reshape both x_train and x_test.\nThe result will convert our array of 2D arrays we started with to an array of 1D arrays with the same values.\nYou should have an x_train_flat and an x_test_flat variable\n\n\n\nStep 5: Train the data\n\nIn the code, the model is already created for you, but you will need to train the model with the reshaped data\nIn order to train the model, run the line model.fit(x, y, epochs=5)\nx: The x value from the training data. In our case, the x should be x_train_flat\ny: The y value from the training data. We can just use y_train for this value\nepochs=5: Specifies the number of times the model will go through the entire training dataset through the training process. Leave this parameter as is\n\n\n\nStep 6: Test and Evaluate Data\n\nNow that the model is trained, we can use our test dataset to evaluate how our model performs\nTo test our model, add the line model.evaluate(x_test_flat, y_test) to the notebook in the provided block\nRunning this line, we get an accuracy around 90% which means our model is very accurate\nNow we can visualize the accuracy using a confusion matrix to see which numbers are more commonly misclassified.\nRun the confusion matrix function at the end of the notebook. It should look like this:\n\n\n\n\nThe y-axis represents the actual number that the image is supposed to be and the x-axis is what the model predicted the image in the number to be. For example, the model predicted 61 of the handwriting images to be a 9.\n\n\nAfter you produce this confusion matrix, push your code to github and email the link to (knguyen07@email.wm.edu)",
    "crumbs": [
      "Machine Learning Homework"
    ]
  }
]